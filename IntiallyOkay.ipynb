{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1345fb40-6f07-420e-895d-847f40f14e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x202d2ecc910>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 1: Imports & Setup\n",
    "# ------------------------------\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "427962b7-f057-4767-bc5e-e89a85f67bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA device: NVIDIA GeForce RTX 3050 4GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 2: Device detection\n",
    "# ------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(\"CUDA device:\", torch.cuda.get_device_name(0))\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10387171-93ef-4de6-939f-116738acb868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Cell 3: Paths & folders\n",
    "# ------------------------------\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"vocab\", exist_ok=True)\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "CORPUS_PATH = \"data/all_hindi_clean.txt\"\n",
    "DATA_PAIRS_PATH = \"data/data_pairs.pkl\"\n",
    "VOCAB_PATH = \"vocab/hindi_vocab.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d2b769c-2130-4916-b32d-fcc2eb2e2b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 sentences (limited to 100000)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 4: Load corpus\n",
    "# ------------------------------\n",
    "MAX_LINES = 100000  # limit\n",
    "\n",
    "if not os.path.exists(CORPUS_PATH):\n",
    "    raise FileNotFoundError(f\"Corpus not found at {CORPUS_PATH}\")\n",
    "\n",
    "sentences = []\n",
    "with open(CORPUS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= MAX_LINES:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            sentences.append(line)\n",
    "\n",
    "print(f\"Loaded {len(sentences)} sentences (limited to {MAX_LINES})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7448a4d8-a565-4717-927a-270681e88813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Cell 5: Create typos function\n",
    "# ------------------------------\n",
    "def create_typos(sentence, typo_prob=0.2):\n",
    "    words = sentence.split()\n",
    "    new_words = []\n",
    "    for w in words:\n",
    "        if random.random() < typo_prob:\n",
    "            typo_type = random.choice([\"delete\", \"replace\", \"transpose\"])\n",
    "            if typo_type == \"delete\" and len(w) > 1:\n",
    "                i = random.randint(0, len(w)-1)\n",
    "                w = w[:i] + w[i+1:]\n",
    "            elif typo_type == \"replace\" and len(w) > 0:\n",
    "                i = random.randint(0, len(w)-1)\n",
    "                w = w[:i] + random.choice(list(w)) + w[i+1:]\n",
    "            elif typo_type == \"transpose\" and len(w) > 1:\n",
    "                i = random.randint(0, len(w)-2)\n",
    "                w = w[:i] + w[i+1] + w[i] + w[i+2:]\n",
    "        new_words.append(w)\n",
    "    return \" \".join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "564588b9-c456-4853-99a2-62f3be45c6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample pair: ('के', 'के')\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 6: Create dataset pairs\n",
    "# ------------------------------\n",
    "data_pairs = [(create_typos(s), s) for s in sentences]\n",
    "print(\"Sample pair:\", data_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45575110-dd19-4d5c-9f6e-ecd0f5e66004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char-level vocab size: 91\n",
      "Character-level vocabulary saved!\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 7: Build char-level vocabulary\n",
    "# ------------------------------\n",
    "\n",
    "# Collect all characters in the dataset\n",
    "all_text = \" \".join(s for _, s in data_pairs)\n",
    "chars = sorted(list(set(all_text)))\n",
    "\n",
    "PAD, SOS, EOS, UNK = \"<PAD>\", \"<SOS>\", \"<EOS>\", \"<UNK>\"\n",
    "\n",
    "vocab = {PAD: 0, SOS: 1, EOS: 2, UNK: 3}\n",
    "for c in chars:\n",
    "    if c not in vocab:\n",
    "        vocab[c] = len(vocab)\n",
    "\n",
    "rev_vocab = {idx: char for char, idx in vocab.items()}\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Char-level vocab size: {vocab_size}\")\n",
    "\n",
    "# Save char vocab\n",
    "with open(VOCAB_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    for char, idx in vocab.items():\n",
    "        f.write(f\"{char}\\t{idx}\\n\")\n",
    "print(\"Character-level vocabulary saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46f46cbc-6725-4de5-bc66-4e56c7412423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data pairs saved!\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 8: Save data pairs\n",
    "# ------------------------------\n",
    "with open(DATA_PAIRS_PATH, \"wb\") as f:\n",
    "    pickle.dump(data_pairs, f)\n",
    "print(\"Data pairs saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5af69837-fedf-47a8-819d-136a4caa4708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Cell 9: Dataset & DataLoader\n",
    "# ------------------------------\n",
    "class HindiSpellDataset(Dataset):\n",
    "    def __init__(self, pairs, vocab):\n",
    "        self.pairs = pairs\n",
    "        self.vocab = vocab\n",
    "        self.SOS = vocab[SOS]\n",
    "        self.EOS = vocab[EOS]\n",
    "        self.UNK = vocab[UNK]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src, tgt = self.pairs[idx]\n",
    "        # char-level tokenization\n",
    "        src_ids = [self.vocab.get(c, self.UNK) for c in src] + [self.EOS]\n",
    "        tgt_ids = [self.SOS] + [self.vocab.get(c, self.UNK) for c in tgt] + [self.EOS]\n",
    "        return torch.tensor(src_ids, dtype=torch.long), torch.tensor(tgt_ids, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    PAD_IDX = vocab[PAD]\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    src_max = max(len(s) for s in src_batch)\n",
    "    tgt_max = max(len(t) for t in tgt_batch)\n",
    "    src_padded = torch.full((len(batch), src_max), PAD_IDX, dtype=torch.long)\n",
    "    tgt_padded = torch.full((len(batch), tgt_max), PAD_IDX, dtype=torch.long)\n",
    "    src_lengths = []\n",
    "    tgt_lengths = []\n",
    "    for i, (s, t) in enumerate(zip(src_batch, tgt_batch)):\n",
    "        src_padded[i, :len(s)] = s\n",
    "        tgt_padded[i, :len(t)] = t\n",
    "        src_lengths.append(len(s))\n",
    "        tgt_lengths.append(len(t))\n",
    "    return src_padded, tgt_padded, torch.tensor(src_lengths), torch.tensor(tgt_lengths)\n",
    "\n",
    "def make_dataloader(pairs, batch_size=16, shuffle=True):\n",
    "    dataset = HindiSpellDataset(pairs, vocab)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn,\n",
    "                        num_workers=0, pin_memory=(device.type==\"cuda\"))\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c7bcf29-7b4c-45aa-ac0b-6bac8ce65ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 100000 sentence pairs (subset)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 10: Subsample dataset for laptop training\n",
    "# ------------------------------\n",
    "TRAIN_SUBSET = 100_000\n",
    "if len(data_pairs) > TRAIN_SUBSET:\n",
    "    data_pairs_subset = random.sample(data_pairs, TRAIN_SUBSET)\n",
    "else:\n",
    "    data_pairs_subset = data_pairs\n",
    "\n",
    "print(f\"Training on {len(data_pairs_subset)} sentence pairs (subset)\")\n",
    "dataloader = make_dataloader(data_pairs_subset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "868c91c2-ffec-41f7-bb78-afab613c2e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Cell 11: Model definition\n",
    "# ------------------------------\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, (h, c) = self.lstm(packed)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
    "        return out, (h, c)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = x.unsqueeze(1)\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        output = self.fc(output.squeeze(1))\n",
    "        return output, hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, src_lengths, tgt, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.size(0)\n",
    "        tgt_len = tgt.size(1)\n",
    "        vocab_size = self.decoder.fc.out_features\n",
    "        outputs = torch.zeros(batch_size, tgt_len, vocab_size, device=self.device)\n",
    "\n",
    "        encoder_out, hidden = self.encoder(src, src_lengths)\n",
    "        input = tgt[:, 0]\n",
    "        for t in range(1, tgt_len):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = tgt[:, t] if teacher_force else top1\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e861582d-4f3c-47fe-97d0-3b4530731591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sh.Pritpal Singh\\AppData\\Local\\Temp\\ipykernel_16996\\3724489151.py:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 12: Initialize model & optimizer\n",
    "# ------------------------------\n",
    "embed_size = 192\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "dropout = 0.1\n",
    "\n",
    "encoder = Encoder(vocab_size, embed_size, hidden_size, num_layers, dropout)\n",
    "decoder = Decoder(vocab_size, embed_size, hidden_size, num_layers, dropout)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab[PAD])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "use_amp = (device.type==\"cuda\")\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b94c9c72-112b-4fe5-a39e-0e049617cd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 5625/5625 [04:09<00:00, 22.54it/s, Loss=0.2035, TF_Ratio=0.90, Batch Time=0.05s, ETA=0.0m]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Average Training Loss: 0.7577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 625/625 [00:05<00:00, 112.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.7081 | Token Accuracy: 86.85%\n",
      "Epoch 1 Validation Loss: 0.7081, Token Accuracy: 86.85%\n",
      "Saved best model checkpoint: checkpoints/seq2seq_best.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 5625/5625 [04:39<00:00, 20.10it/s, Loss=0.3037, TF_Ratio=0.80, Batch Time=0.04s, ETA=0.0m]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Average Training Loss: 0.3022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 625/625 [00:06<00:00, 98.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.5745 | Token Accuracy: 88.47%\n",
      "Epoch 2 Validation Loss: 0.5745, Token Accuracy: 88.47%\n",
      "Saved best model checkpoint: checkpoints/seq2seq_best.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 5625/5625 [05:18<00:00, 17.66it/s, Loss=0.1857, TF_Ratio=0.70, Batch Time=0.07s, ETA=0.0m]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Average Training Loss: 0.2615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 625/625 [00:08<00:00, 73.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.4648 | Token Accuracy: 90.42%\n",
      "Epoch 3 Validation Loss: 0.4648, Token Accuracy: 90.42%\n",
      "Saved best model checkpoint: checkpoints/seq2seq_best.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5625/5625 [05:55<00:00, 15.80it/s, Loss=0.1173, TF_Ratio=0.60, Batch Time=0.05s, ETA=0.0m]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 Average Training Loss: 0.2436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 625/625 [00:06<00:00, 96.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.4116 | Token Accuracy: 91.42%\n",
      "Epoch 4 Validation Loss: 0.4116, Token Accuracy: 91.42%\n",
      "Saved best model checkpoint: checkpoints/seq2seq_best.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 5625/5625 [05:12<00:00, 18.02it/s, Loss=0.2409, TF_Ratio=0.50, Batch Time=0.05s, ETA=0.0m]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 Average Training Loss: 0.2377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 625/625 [00:05<00:00, 109.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.3889 | Token Accuracy: 91.62%\n",
      "Epoch 5 Validation Loss: 0.3889, Token Accuracy: 91.62%\n",
      "Saved best model checkpoint: checkpoints/seq2seq_best.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 5625/5625 [05:10<00:00, 18.12it/s, Loss=0.2860, TF_Ratio=0.50, Batch Time=0.05s, ETA=0.0m]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 Average Training Loss: 0.2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 625/625 [00:05<00:00, 116.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.3828 | Token Accuracy: 91.79%\n",
      "Epoch 6 Validation Loss: 0.3828, Token Accuracy: 91.79%\n",
      "Saved best model checkpoint: checkpoints/seq2seq_best.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 5625/5625 [05:08<00:00, 18.26it/s, Loss=0.1998, TF_Ratio=0.50, Batch Time=0.06s, ETA=0.0m]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 Average Training Loss: 0.2060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 625/625 [00:07<00:00, 85.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.3708 | Token Accuracy: 92.16%\n",
      "Epoch 7 Validation Loss: 0.3708, Token Accuracy: 92.16%\n",
      "Saved best model checkpoint: checkpoints/seq2seq_best.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 5625/5625 [04:33<00:00, 20.58it/s, Loss=0.1393, TF_Ratio=0.50, Batch Time=0.02s, ETA=0.0m]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 Average Training Loss: 0.1941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 625/625 [00:04<00:00, 135.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.3668 | Token Accuracy: 92.36%\n",
      "Epoch 8 Validation Loss: 0.3668, Token Accuracy: 92.36%\n",
      "Saved best model checkpoint: checkpoints/seq2seq_best.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5625/5625 [04:53<00:00, 19.18it/s, Loss=0.2447, TF_Ratio=0.50, Batch Time=0.05s, ETA=0.0m]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 Average Training Loss: 0.1832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 625/625 [00:05<00:00, 118.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.3672 | Token Accuracy: 92.36%\n",
      "Epoch 9 Validation Loss: 0.3672, Token Accuracy: 92.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 5625/5625 [04:53<00:00, 19.19it/s, Loss=0.1288, TF_Ratio=0.50, Batch Time=0.03s, ETA=0.0m]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 Average Training Loss: 0.1756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 625/625 [00:04<00:00, 128.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.3659 | Token Accuracy: 92.53%\n",
      "Epoch 10 Validation Loss: 0.3659, Token Accuracy: 92.53%\n",
      "Saved best model checkpoint: checkpoints/seq2seq_best.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 13: Improved Training Loop with Validation & Scheduled Teacher Forcing\n",
    "# ------------------------------\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "max_grad_norm = 1.0\n",
    "accum_steps = 2  # simulate larger batch size\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Split train/validation\n",
    "random.shuffle(data_pairs)\n",
    "split_idx = int(0.9 * len(data_pairs))\n",
    "train_pairs = data_pairs[:split_idx]\n",
    "val_pairs = data_pairs[split_idx:]\n",
    "\n",
    "train_loader = make_dataloader(train_pairs, batch_size=16)\n",
    "val_loader = make_dataloader(val_pairs, batch_size=16, shuffle=False)\n",
    "\n",
    "# Scheduled teacher forcing\n",
    "def get_teacher_forcing_ratio(epoch, max_epochs=num_epochs):\n",
    "    # start at 1.0, decay to 0.5\n",
    "    return max(0.5, 1.0 - epoch/max_epochs)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    start_time = time.time()\n",
    "    teacher_forcing_ratio = get_teacher_forcing_ratio(epoch)\n",
    "    \n",
    "    batch_iterator = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch}\")\n",
    "    \n",
    "    for batch_idx, (src, tgt, src_lengths, tgt_lengths) in batch_iterator:\n",
    "        batch_start = time.time()\n",
    "        \n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        src_lengths, tgt_lengths = src_lengths.to(device), tgt_lengths.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=use_amp):\n",
    "            output = model(src, src_lengths, tgt, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:,1:].reshape(-1, output_dim)\n",
    "            tgt_target = tgt[:,1:].reshape(-1)\n",
    "            loss = criterion(output, tgt_target) / accum_steps\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (batch_idx + 1) % accum_steps == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        epoch_loss += loss.item() * accum_steps\n",
    "        \n",
    "        batch_time = time.time() - batch_start\n",
    "        elapsed = time.time() - start_time\n",
    "        avg_batch_time = elapsed / (batch_idx + 1)\n",
    "        remaining_batches = len(train_loader) - batch_idx - 1\n",
    "        eta = remaining_batches * avg_batch_time\n",
    "        \n",
    "        batch_iterator.set_postfix({\n",
    "            \"Loss\": f\"{loss.item()*accum_steps:.4f}\",\n",
    "            \"TF_Ratio\": f\"{teacher_forcing_ratio:.2f}\",\n",
    "            \"Batch Time\": f\"{batch_time:.2f}s\",\n",
    "            \"ETA\": f\"{eta/60:.1f}m\"\n",
    "        })\n",
    "\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"\\nEpoch {epoch} Average Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, vocab, device)\n",
    "    print(f\"Epoch {epoch} Validation Loss: {val_loss:.4f}, Token Accuracy: {val_acc*100:.2f}%\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        ckpt_path = f\"checkpoints/seq2seq_best.pt\"\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"vocab\": vocab\n",
    "        }, ckpt_path)\n",
    "        print(f\"Saved best model checkpoint: {ckpt_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0075a959-7898-40bf-a73f-d2ddb7e5b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), 'encoder_state_dict.h5')\n",
    "torch.save(decoder.state_dict(), 'decoder_state_dict.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0191271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sh.Pritpal Singh\\AppData\\Local\\Temp\\ipykernel_16996\\3682171628.py:96: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BEST checkpoint from checkpoints/seq2seq_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 6250/6250 [02:45<00:00, 37.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation Result ===\n",
      "Avg Loss       : 0.2541\n",
      "Char Accuracy  : 94.38%\n",
      "==========================\n",
      "\n",
      "Input     : रॉलिंग\n",
      "Target    : रॉलिंग\n",
      "Predicted : रॉलिंग\n",
      "------------------------------------------------------------\n",
      "Input     : कनका\n",
      "Target    : कनका\n",
      "Predicted : कनका\n",
      "------------------------------------------------------------\n",
      "Input     : तम्बोली\n",
      "Target    : तम्बोली\n",
      "Predicted : तम्बोली\n",
      "------------------------------------------------------------\n",
      "Input     : ओल्मपियन\n",
      "Target    : ओलम्पियन\n",
      "Predicted : ओल्मपियन\n",
      "------------------------------------------------------------\n",
      "Input     : पुश्तैनी\n",
      "Target    : पुश्तैनी\n",
      "Predicted : पुश्तैनी\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 14: Evaluation (Improved)\n",
    "# ------------------------------\n",
    "def evaluate(model, dataloader, criterion, vocab, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_items = 0      # number of sequences\n",
    "    total_tokens = 0\n",
    "    correct_tokens = 0\n",
    "\n",
    "    PAD_IDX = vocab[\"<PAD>\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt, src_lengths, tgt_lengths in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            src_lengths, tgt_lengths = src_lengths.to(device), tgt_lengths.to(device)\n",
    "\n",
    "            # forward pass (no teacher forcing)\n",
    "            output = model(src, src_lengths, tgt, teacher_forcing_ratio=0.0)\n",
    "\n",
    "            # flatten for CE loss\n",
    "            output_dim = output.shape[-1]\n",
    "            output_flat = output[:, 1:].reshape(-1, output_dim)\n",
    "            tgt_flat = tgt[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output_flat, tgt_flat)\n",
    "\n",
    "            batch_size = src.size(0)\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_items += batch_size\n",
    "\n",
    "            # accuracy (char-level)\n",
    "            pred_tokens = output_flat.argmax(dim=1)\n",
    "            mask = tgt_flat != PAD_IDX\n",
    "\n",
    "            correct_tokens += (pred_tokens[mask] == tgt_flat[mask]).sum().item()\n",
    "            total_tokens += mask.sum().item()\n",
    "\n",
    "    # final metrics\n",
    "    avg_loss = total_loss / max(1, total_items)\n",
    "    accuracy = correct_tokens / max(1, total_tokens)\n",
    "\n",
    "    print(f\"\\n=== Evaluation Result ===\")\n",
    "    print(f\"Avg Loss       : {avg_loss:.4f}\")\n",
    "    print(f\"Char Accuracy  : {accuracy * 100:.2f}%\")\n",
    "    print(\"==========================\\n\")\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "\n",
    "def decode_sequence(ids, rev_vocab):\n",
    "    \"\"\"\n",
    "    Convert ID list → Hindi string (character-level)\n",
    "    Ignore special tokens.\n",
    "    \"\"\"\n",
    "    ignore = {vocab[\"<PAD>\"], vocab[\"<SOS>\"], vocab[\"<EOS>\"]}\n",
    "    chars = [rev_vocab.get(i, \"\") for i in ids if i not in ignore]\n",
    "    return \"\".join(chars)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def show_sample_predictions(model, dataloader, rev_vocab, num_samples=5):\n",
    "    model.eval()\n",
    "    shown = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for src, tgt, src_lengths, tgt_lengths in dataloader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            src_lengths = src_lengths.to(device)\n",
    "\n",
    "            output = model(src, src_lengths, tgt, teacher_forcing_ratio=0.0)\n",
    "            pred_ids = output.argmax(dim=-1)\n",
    "\n",
    "            for i in range(src.size(0)):\n",
    "                src_txt = decode_sequence(src[i].cpu().tolist(), rev_vocab)\n",
    "                tgt_txt = decode_sequence(tgt[i].cpu().tolist(), rev_vocab)\n",
    "                pred_txt = decode_sequence(pred_ids[i].cpu().tolist(), rev_vocab)\n",
    "\n",
    "                print(\"Input     :\", src_txt)\n",
    "                print(\"Target    :\", tgt_txt)\n",
    "                print(\"Predicted :\", pred_txt)\n",
    "                print(\"-\" * 60)\n",
    "\n",
    "                shown += 1\n",
    "                if shown >= num_samples:\n",
    "                    return\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Load checkpoint (optional)\n",
    "# ------------------------------\n",
    "ckpt_path = \"checkpoints/seq2seq_best.pt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model_state\"])\n",
    "print(f\"Loaded BEST checkpoint from {ckpt_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Evaluate on the same subset\n",
    "# ------------------------------\n",
    "evaluate(model, dataloader, criterion, vocab, device)\n",
    "\n",
    "# Show sample predictions\n",
    "show_sample_predictions(model, dataloader, rev_vocab, num_samples=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.9 (torch GPU)",
   "language": "python",
   "name": "torch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
